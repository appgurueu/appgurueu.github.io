<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Statistik &amp; Stochastik</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <script src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
    var mathElements = document.getElementsByClassName("math");
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") { katex.render(texText.data, mathElements[i], { displayMode: mathElements[i].classList.contains("display"), throwOnError: false } );
    }}});</script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" />
</head>
<body>
<header id="title-block-header">
<h1 class="title">Statistik &amp; Stochastik</h1>
</header>
<h2 id="definitionen">Definitionen</h2>
<ul>
<li>Klasse: Zusammenfassung mehrerer Ereignisse zu einer Klasse</li>
<li>Absolute Häufigkeit: Anzahl der Vorkomnisse eines Ereignisses</li>
<li>Relative Häufigkeit: Absolute Häufigkeit geteilt durch die insgesamte Anzahl der Ereignisse</li>
<li>Wahrscheinlichkeit: Idealwert der relativen Häufigkeit. Die relative Häufigkeit nähert sich mit steigender Ereignisanzahl immer weiter der Häufigkeit an (“Gesetz der großen Zahlen”).</li>
<li>Wahrscheinlichkeitsdichte: Wahrscheinlichkeit geteilt durch Klassenbreite.</li>
</ul>
<p>Für eine Zufallsgröße <span class="math inline">X</span> mit den Werten <span class="math inline">x_1, x_2, x_n</span> sei definiert als Erwartungswert von <span class="math inline">X</span>:</p>
<p><span class="math inline">\mu = x_1P(X = x_1) + x_2P(X = x_2) + ... + x_nP(X = x_n)</span></p>
<p>und</p>
<p><span class="math inline">\sigma = \sqrt{(x_1 - \mu)^2P(X = x_1) + (x_2 - \mu)^2P(X = x_2) + ... + (x_n - \mu)^2P(X = x_n)}</span></p>
<p>als Standardabweichung.</p>
<h3 id="fakultät">Fakultät</h3>
<p>Die Fakultät <span class="math inline">n! = \prod_{i=1}^n{i} = 1 \cdot 2 \cdot ... \cdot n</span> einer Zahl gibt die Anzahl der möglichen Permutationen (verschiedenen Anordnungen) eines “Tupels” mit <span class="math inline">n</span> verschiedenen Elementen an. So ist bspw. <span class="math inline">3! = 6</span>, da jedes 3-er-Tupel (Tripel) <span class="math inline">(a, b, c)</span> 6 mögliche Reihenfolgen besitzt:</p>
<ul>
<li><span class="math inline">(a, b, c)</span></li>
<li><span class="math inline">(a, c, b)</span></li>
<li><span class="math inline">(b, a, c)</span></li>
<li><span class="math inline">(b, c, a)</span></li>
<li><span class="math inline">(c, a, b)</span></li>
<li><span class="math inline">(c, b, a)</span></li>
</ul>
<p>Intuitiv ist die Begründung der Formel klar: Es gibt <span class="math inline">n</span> Möglichkeiten, das erste Element auszuwählen. Es bleiben dann <span class="math inline">n - 1</span> Möglichkeiten, das zweite Element auszuwählen. Beim vorletzten Element schließlich bleiben nur noch zwei Wahlmöglichkeiten, beim letzten gar nur noch eine, also <span class="math inline">n! = n \cdot (n - 1) \cdot ... \cdot 2 \cdot 1</span>. Diese “Wahlmöglichkeiten” werden nun multipliziert. Nach dieser Intuition ist auch klar, warum die Fakultät häufig bei Zufallsexperimenten ohne Zurücklegen zur Anwendung kommt.</p>
<h3 id="binomialkoeffizient">Binomialkoeffizient</h3>
<p><span class="math display">
{n \choose k} = \frac{n!}{k!(n-k)!}
</span></p>
<p>Gesprochen “<span class="math inline">n</span> über <span class="math inline">k</span>” oder <strong>“wähle <span class="math inline">k</span> aus <span class="math inline">n</span>”</strong>.</p>
<p>Intuitiv: Gibt an, auf wieviele Arten man aus <span class="math inline">n</span> Elementen <span class="math inline">k</span> auswählen kann, ohne Beachtung der Reihenfolge der <span class="math inline">k</span> Elemente untereinander oder der übrigen <span class="math inline">n-k</span> Elemente untereinander.</p>
<p>Im Baumdiagramm einer binomialverteilten Zufallsgröße mit zwei Ereignissen, Erfolg und Misserfolg: <span class="math inline">{n \choose k}</span> gibt die Anzahl der Pfade an, bei denen eines der beiden Ereignisse bei <span class="math inline">n</span>-facher Wiederholung genau <span class="math inline">k</span>-mal auftritt.</p>
<p>Beispiel: <span class="math inline">{3 \choose 2} = \frac{3!}{2!(3-2)!} = \frac{6}{3} = 2</span>, da es drei Möglichkeiten gibt, zwei Elemente aus drei zu wählen (<code>110</code>, <code>011</code>, <code>101</code>).</p>
<h3 id="baumdiagramm">Baumdiagramm</h3>
<p>Pfadregeln:</p>
<ul>
<li>Multiplizieren von Wahrscheinlichkeiten entlang eines Pfades</li>
<li>Addieren von Wahrscheinlichkeiten auf der gleichen Ebene</li>
</ul>
<h2 id="bernoulli-experimente-binomialverteilung">Bernoulli-Experimente / Binomialverteilung</h2>
<p>Definition: Ein Zufallsexperiment mit nur zwei möglichen Ergebnissen: “Erfolg” oder “Misserfolg”. Dabei gilt <span class="math inline">P(Erfolg) = p</span> und <span class="math inline">P(Misserfolg) = q</span> mit <span class="math inline">p + q = 1</span>.</p>
<p>Wird ein Bernoulli-Experiment <span class="math inline">n</span>-Mal durchgeführt und ändert sich die Wahrscheinlichkeit von Stufe zu Stufe nicht, so spricht man von einem <span class="math inline">n</span>-stufigen Bernoulli-Experiment (= Bernoulli-Kette).</p>
<p><span class="math inline">P(X = k)</span> mit <span class="math inline">k</span> Anzahl der Erfolge lässt sich als <span class="math inline">{n \choose k}p^kq^{n-k}</span> berechnen (entsprechend den Pfadregeln im Baumdiagramm: Die Wahrscheinlichkeiten aller Pfade mit genau <span class="math inline">k</span> Erfolgen sind gleich - nämlich <span class="math inline">p^kq^{n-k}</span>. Mithilfe des Binomialkoeffizienten bestimmt man die Anzahl dieser Pfade, mit der noch multipliziert wird).</p>
<ul>
<li>Erwartungswert: <span class="math inline">\mu = p \cdot n</span></li>
<li>Standardabweichung: <span class="math inline">\sigma = \sqrt{p \cdot q \cdot n}</span></li>
</ul>
<p>Bei gegebenen Wahrscheinlichkeiten <span class="math inline">p</span> (bzw. <span class="math inline">q</span>) sowie <span class="math inline">k</span> lässt sich ein notwendiger “Stichprobenumfang” <span class="math inline">n</span> berechnen, damit ein gewisses Ereignis eine gewisse Wahrscheinlichkeit <span class="math inline">y</span> besitzt. Bspw. für mindestens einen Erfolg:</p>
<p><span class="math display">
P(x \geq 1) = y \\
1 - P(X = 0) = y \\
1 - q^n = y \\
q^n = 1 - y \\
n = log_q(1 - y)
</span></p>
<p>Der erhaltene Wert für den Stichprobenumfang <span class="math inline">n</span> muss <em>aufgerundet</em> werden, da <em>mindestens</em> ein Erfolg erreicht werden soll.</p>
<p><strong>Kumulierte Wahrscheinlichkeiten</strong>, d.h. die Wahrscheinlichkeit, dass die Anzahl der Erfolge in einem bestimmten Bereich liegt, können auf zwei Arten ausgerechnet werden:</p>
<ul>
<li>Falls möglich mit dem <a href="#gtr">GTR</a> und <code>binomcdf</code></li>
<li>Alternativ als Summe der Einzelwahrscheinlichkeiten für genau <span class="math inline">k</span> Erfolge für alle <span class="math inline">k</span> aus dem Bereich</li>
<li>In einigen Sonderfällen lässt sich mit der Gegenwahrscheinlichkeit rechnen, wenn der Gegenbereich wesentlich kleiner ist. Bsp.: Bis zu 9 Erfolge bei 10 Durchführungen ⇒ Gegenereignis: Genau 10 Erfolge ⇒ <span class="math inline">P(X \leq 9) = 1 - P(X = 10)</span> für <span class="math inline">x</span> Anzahl der Erfolge; <span class="math inline">P(X = 10)</span> lässt sich mit der bekannten Formel berechnen.</li>
</ul>
<h2 id="beurteilende-statistik">Beurteilende Statistik</h2>
<p>In der beurteilenden Statistik ist das Ziel, mit möglichst hoher Sicherheit von einer kleinen <em>Stichprobe</em> auf die <em>Gesamtheit</em> zu schließen.</p>
<p>Voraussetzung: Binomialverteilte Zufallsgröße <span class="math inline">X</span>.</p>
<p>Vorgehensweise bei <em>Signifikanztests / Hypothesentests</em>:</p>
<ol type="1">
<li>Hypothesen formulieren: Die zu überprüfende Hypothese <span class="math inline">H_0</span> nennt man Nullhypothese, das Gegenteil <span class="math inline">H_1</span> Alternativhypothese. Die Nullhypothese zu verwerfen bestätigt die Alternativhypothese.
<ul>
<li>Hypothesen treffen auf Schule immer eine Aussage über die Wahrscheinlichkeit <span class="math inline">p</span>
<ul>
<li>Beim zweiseitigen Test “gleich”, bspw. <span class="math inline">p = 0,5</span> als Hypothese für die Erfolgswahrscheinlichkeit beim Münzwurf</li>
<li>Beim einseitigen Test größer/kleiner, bspw. <span class="math inline">p \leq 0,5</span> oder <span class="math inline">p \geq 0,5</span></li>
</ul></li>
<li>Da man mit relativer Sicherheit nur Hypothesen <em>verwerfen</em> kann, wählt man die Hypothese, die gestützt werden soll, als Nullhypothese und entsprechend das Gegenteil als Alternativhypothese.</li>
</ul></li>
<li>Festlegung des <em>Signifikanzniveaus <span class="math inline">S</span></em>, üblicherweise <span class="math inline">5\%</span> oder <span class="math inline">1\%</span>. Die <em>maximale Irrtumswahrscheinlichkeit <span class="math inline">\alpha</span></em> darf höchstens so groß wie <span class="math inline">S</span> sein, es gilt <span class="math inline">\alpha \leq S</span>.
<ul>
<li>Als <em>Irrtumswahrscheinlichkeit</em> bezeichnet man die Wahrscheinlichkeit, dass eine Hypothese <em>fälschlicherweise abgelehnt/verworfen wird (Fehler 1. Art)</em>.
<ul>
<li>Berechnung über <em>Größe des Ablehnungsbereiches</em>: Kumulierte Wahrscheinlichkeit, dass ein Wert - unter der Annahme, dass die Nullhypothese gilt - im Ablehnungsbereich liegt.</li>
</ul></li>
<li>Die <em>Wahrscheinlichkeit <span class="math inline">\beta</span></em> gibt an, wie wahrscheinlich es ist, dass eine falsche Nullhypothese <em>fälschlicherwise <strong>nicht</strong> abgelehnt wird (Fehler 2. Art)</em>.
<ul>
<li>Berechnung über <em>tatsächliche Erfolgswahrscheinlichkeit <span class="math inline">p</span></em> und die <em>Größe des Annahmebereichs</em> als <em>Wahrscheinlichkeit, dass ein Wert im Annahmebereich liegt</em></li>
</ul></li>
</ul></li>
<li>Bestimmung der Sigma-Umgebung zum Signifikanzniveau (<span class="math inline">95\%</span>-Umgebung für <span class="math inline">S=5\%</span>, <span class="math inline">99\%</span>-Umgebung für <span class="math inline">S=1\%</span>)
<ul>
<li>Dabei muss so gerundet werden, dass <span class="math inline">\alpha \leq S</span> nicht verletzt wird; in der Umgebung müssen also <em>mindestens</em> <span class="math inline">95\%</span> bzw. <span class="math inline">99\%</span> der Werte liegen.</li>
<li>Man erhält als <em>Annahmebereich</em> (bzw. eher “Nicht-Ablehnungsbereich”) die Sigma-Umgebung und als <em>Ablehnungs- / Verwerfungsbereich</em> alles jenseits der Sigma-Umgebung.
<ul>
<li>Beim zweiseitigen Hypothesentest finden sich Ablehnungsbereiche auf beiden Seiten, beim einseitigen nur auf einer.</li>
<li>Beim <em>rechtsseitigen</em> Test liegt der Ablehnungsbereich <em>rechts</em>, beim <em>linksseitigen</em> Tests analog <em>links</em></li>
</ul></li>
</ul></li>
<li>Formulierung der <em>Entscheidungsregel</em>: Liegt der tatsächliche Wert für <span class="math inline">X</span> in der Stichprobe im <em>Ablehnungsbereich</em> wird die Nullhypothese verworfen und stattdessen die Alternativhypothese bestätigt. Falls der Wert im <em>Annahmebereich</em> liegt, reicht dies nicht, um die Nullhypothese zu bestätigen; die Nullhypothese wird dann lediglich <em>(noch) nicht abgelehnt</em>.</li>
<li>Anwendung der Entscheidungsregel: Trivial.</li>
</ol>
<p>Zweiseitiger Hypothesentest für <span class="math inline">H_0: p = 0,5</span>, Ablehnungsbereich rot, Annahmebereich grau:</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b2/BinomialTest.svg/1024px-BinomialTest.svg.png" width="4em" height="4em"></p>
<p>Ist die Laplace-Bedingung nicht erfüllt, müssen die Annahme- und Ablehnungsbereiche ohne die Sigmaregeln bestimmt werden. Dies ist bspw. mit <code>nsolve</code> im GTR möglich:</p>
<p>Für linksseitigen Ablehnungsbereich der Größe <span class="math inline">10\% = 0.1</span> mit <span class="math inline">n = 42</span> und <span class="math inline">p = 0,69</span>: <code>nsolve(binomcdf(42, 0.69, 0, x) = 0.1, x, 0, 42)</code>.</p>
<p>Zusätzliche Überlegung im Anwendungskontext: Folgenschwerster Fehler soll der Fehler 1. Art sein, da dessen Wahrscheinlichkeit begrenzt werden kann.</p>
<p>Bspw.: Die Nebenwirkungen eines Medikaments sollen weniger wahrscheinlich sein als ein bestimmtes <span class="math inline">p</span>. Die Wahrscheinlichkeit zu gering anzugeben, wäre hier der folgenschwerste Fehler. Damit dies der Fehler 1. Art (fälschliches Ablehnen der Nullhypothese) ist, muss die Nullhypothese lauten, dass die Wahrscheinlichkeit <em>größer</em> als eine vermutete obere Grenze ist. Verwirft man dann die Nullhypothese, bietet einem das Signifikanzniveau eine relative hohe Sicherheitswahrscheinlichkeit für die Gültigkeit der Alternativhypothese, nämlich dass die Wahrscheinlichkeit für Nebenwirkungen <em>unter</em> der oberen Grenze liegt.</p>
<h2 id="stetige-zufallsgrößen">Stetige Zufallsgrößen</h2>
<p>Können alle Werte in einem reellen Intervall angenommen werden - existiert also zwischen zwei möglichen Werten immer ein weiterer - so spricht man von einer stetigen Zufallgröße.</p>
<p>Demzufolge ist die Wahrscheinlichkeit für genau einen Wert geht gegen <span class="math inline">0</span>: Unter unendlich vielen möglichen anderen Werten ist es unendlich unwahrscheinlich, dass genau dieser Wert angenommen wird.</p>
<p>Es ist nur sinnvoll, die Wahrscheinlichkeit dafür anzugeben, dass die stetige Zufallsgröße in einem gewissen <strong>Bereich <span class="math inline">[a; b]</span></strong> liegt.</p>
<p>Eine <strong>Dichtefunktion</strong> gibt - ähnlich wie ein Histogramm - für einen Wert <span class="math inline">x</span> die Wahrscheinlichkeitsdichte an; anders als beim Histogramm sind die Klassen hier allerdings “unendlich klein”.</p>
<p>Für eine solche Dichtefunktion <span class="math inline">f</span> gilt:</p>
<ul>
<li><span class="math inline">f(x) \geq 0 \forall x \in R</span> (Dichten müssen offensichtlich positiv sein - negative Dichten wären sinnlos) und</li>
<li><span class="math inline">\int_a^b f(x)dx</span> ist die Wahrscheinlichkeit für <span class="math inline">x \in [a; b]</span>; somit ist <span class="math inline">\int_{-\infty}^{+\infty} f(x) dx = 1</span> (Gesamtwahrscheinlichkeit 1)</li>
</ul>
<p>Der <strong>Erwartungswert</strong> ist dann als <span class="math inline">\mu = \int_{-\infty}^{+\infty} x f(x) dx</span> definiert,<br />
die <strong>Standardabweichung</strong> als <span class="math inline">\sigma = \sqrt{\int_{-\infty}^{+\infty} (x - \mu)^2 f(x) dx}</span>.</p>
<p>(Generalisierung der Formeln von diskreten Summen hin zu Integralen auf stetigen Funktionen)</p>
<p>Tatsächlich sind die hier angegebenen unendlichen Integrale meist endlich, da <span class="math inline">f</span> für alle <span class="math inline">x</span> außerhalb eines bestimmten Bereiches <span class="math inline">[a; b]</span> meist als <span class="math inline">0</span> definiert wird. Dann ist das Integral von <span class="math inline">-\infty</span> zu <span class="math inline">+\infty</span> gleich dem Integral von <span class="math inline">a</span> bis <span class="math inline">b</span>, welches nun mit dem GTR berechnet werden kann.</p>
<h3 id="normalverteilung">Normalverteilung</h3>
<p>Stetige, normalverteilte Zufallsgrößen besitzen die “Gaußsche Glockenfunktion” <span class="math inline">\psi_{\mu; \sigma}(x) = \frac{1}{\sigma\sqrt{2\pi}} \cdot e^\frac{(x - \mu)^2}{2\sigma^2}</span> als Dichtefunktion.</p>
<p>Es folgt aus dem Funktionsterm:</p>
<ul>
<li>Höhepunkt beim Erwartungswert <span class="math inline">\mu</span>, symmetrisch zur Geraden <span class="math inline">x = \mu</span></li>
<li>Wendepunkte bei <span class="math inline">x = \mu \plusmn \sigma</span></li>
<li>Je größer die Standardabweichung, desto “flacher” die Glockenfunktion</li>
<li>Im Unendlichen (positiv und negativ) geht die Glockenfunktion gegen <span class="math inline">0</span></li>
</ul>
<h4 id="moivre-laplace-näherungsformeln">Moivre-Laplace-Näherungsformeln</h4>
<p>Ist die <strong>Laplace-Bedingung</strong> <span class="math inline">\sigma &gt; 3</span> erfüllt, so lässt sich eine Binomialverteilung mit einer Normalverteilung approximieren (und umgekehrt):</p>
<ul>
<li><span class="math inline">P(X = k) \approx \psi_{\mu; \sigma}(k)</span></li>
<li><span class="math inline">P(a \leq X \leq b) \approx \int_{a-0,5}^{b+0,5} \psi_{\mu; \sigma}(x) dx</span></li>
</ul>
<p>Die nötige Verschiebung der Intervallgrenzen um <span class="math inline">0,5</span> (um in der “Mitte der Balken” anzusetzen) nennt man <strong>Stetigkeitskorrektur</strong>.</p>
<p>Die Binomialverteilung (auf Schule) darf dennoch nicht mit der Normalverteilung verwechselt werden: Erstere ist eine Verteilung einer <strong>diskreten</strong> Zufallsgröße und kann also nur ganzzahlige Werte annehmen - letztere ist eine Verteilung einer <strong>stetigen</strong> Zufallsgröße und kann also beliebige reelle Zahlen als Werte annehmen.</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b7/Binomial_Distribution.svg/1024px-Binomial_Distribution.svg.png" width="4em" height="4em"></p>
<h4 id="sigma-umgebungen">Sigma-Umgebungen</h4>
<p><em>Sicherheitswahrscheinlichkeit</em>: Wahrscheinlichkeit, dass ein zufälliger Wert - gemäß der Verteilung - in der Umgebung (im Intervall) liegt</p>
<p>Für normalverteilte Zufallsgrößen gelten die folgenden Regeln für Sicherheitswahrscheinlichkeiten:</p>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\sigma</span>-Umgebung</th>
<th>Wahrscheinlichkeit</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">[\mu - \sigma; \mu + \sigma]</span></td>
<td><span class="math inline">68,3\%</span></td>
</tr>
<tr class="even">
<td><span class="math inline">[\mu - 2\sigma; \mu + 2\sigma]</span></td>
<td><span class="math inline">95,5\%</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">[\mu - 3\sigma; \mu + 3\sigma]</span></td>
<td><span class="math inline">99,7\%</span></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th>Wahrscheinlichkeit</th>
<th><span class="math inline">\sigma</span>-Umgebung</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">90\%</span></td>
<td><span class="math inline">[\mu - 1,64\sigma; \mu + 1,64\sigma]</span></td>
</tr>
<tr class="even">
<td><span class="math inline">95\%</span></td>
<td><span class="math inline">[\mu - 1,94\sigma; \mu + 1,94\sigma]</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">99\%</span></td>
<td><span class="math inline">[\mu - 2,58\sigma; \mu + 2,58\sigma]</span></td>
</tr>
</tbody>
</table>
<p>Die Wahrscheinlichkeiten und Koeffizienten für Sigma sind hier nur ungefähr angegeben.</p>
<p>Aufgrund der <a href="#moivre-laplace-näherungsformeln">Moivre-Laplace-Näherungsformeln</a> lassen sich die Sigmaregeln - insofern die Laplace-Bedingung erfüllt ist - auch auf <strong>Binomialverteilungen</strong> anwenden; dann müssen die Intervallgrenzen allerdings gerundet werden. Hierfür gilt: Symmetrie - falls nicht explizit gefordert - <strong>nicht beachten</strong>, mit GTR ab-und aufgerundete Intervallgrenzen <strong>ausprobieren</strong>; sind die Wahrscheinlichkeiten Mindestwerte, wird normalerweise betraglich <em>aufgerundet</em>.</p>
<h2 id="visualisierungen">Visualisierungen</h2>
<ul>
<li>Strich- und Balkendiagramme: Zeigen relative Häufigkeiten von Ereignissen oder Ereignisklassen.</li>
<li>Kreisdiagramme: Anteilige Darstellung relativer Häufigkeiten.</li>
<li>Histogramme: Für Intervalle als Ereignisklassen:
<ul>
<li>Breite der Balken entspricht der Breite der Ereignisklasse;</li>
<li>Fläche der Balken entspricht der Wahrscheinlichkeit bzw. relativen Häufigkeit;</li>
<li>Die Höhe der Balken ist somit nicht mehr die Wahrscheinlichkeit sondern die <em>Wahrscheinlichkeitsdichte</em>.</li>
<li>Wahl der Klassen:
<ul>
<li>Klassen müssen weiterhin geschickt gewählt werden</li>
<li>Zu kleine Klassen scheitern daran, Häufungen als erhöhte Wahrscheinlichkeitsdichte zu zeigen
<ul>
<li>Extremfall: Minimale Klassen, genau zwei verschiedene Dichten</li>
</ul></li>
<li>Zu große Klassen dahingegen bieten nicht genügend Granularität
<ul>
<li>Extremfall: Zwei Klassen lassen nur den Vergleich der beiden Klassen zu</li>
</ul></li>
</ul></li>
<li>⇒ Histogramme sind - anders als Strich-, Balken- und Kreisdiagramme - <strong>nicht optisch irreführend</strong> (zumindest bei geeigneter Wahl der Klassen)</li>
</ul></li>
</ul>
<h2 id="hilfsmittel">Hilfsmittel</h2>
<h3 id="formelsammlung">Formelsammlung</h3>
<p>Stochastik auf S. 36 - S. 51. Relevant davon sind:</p>
<ul>
<li>S. 36 zu <strong>Visualisierungen</strong></li>
<li>S. 37 zu <strong>Fakultät, Binomialkoeffizient etc.</strong></li>
<li>S. 38 mit weiteren <strong>Definitionen von Grundbegriffen</strong></li>
<li>S. 39: <strong>Standardabweichung</strong>, “Rechenregeln” für Baumdiagramme</li>
<li>S. 40: <strong>Wahrscheinlichkeitsrechnung</strong></li>
<li>S. 41: <strong>Wahrscheinlichkeitsverteilung</strong>, <strong>Binomialverteilung</strong></li>
<li>S. 42: <strong>Normalverteilung</strong>, Näherungsformel für Binomialverteilungen</li>
<li>S. 43: <strong>Testen von Hypothesen</strong></li>
</ul>
<p>Auf den übrigen Seiten 44 - 51 finden sich hauptsächlich durch den GTR obsolet gewordene Wertetabellen. Nur auf S. 50 findet sich noch etwas zur <strong>Standardnormalverteilung</strong> (allerdings weitestgehend redundant mit S. 42).</p>
<p>Es ist davon auszugehen, dass im hilfsmittelfreien Teil keine äußerst rechenintensiven Normalverteilungen oder Sigma-Umgebungen vorkommen, durchaus aber die Berechnung von binomialverteilten Zufallsgrößen für kleine Werte oder die Angabe von Termen; einfach zu integrierende Dichtefunktionen sind ebenfalls denkbar.</p>
<h3 id="gtr">GTR</h3>
<ul>
<li><code>binompdf(n, p, x)</code>
<ul>
<li><code>n</code>: Anzahl Versuche</li>
<li><code>p</code>: Erfolgswahrscheinlichkeit</li>
<li><code>x</code>: Anzahl Erfolge</li>
</ul></li>
<li><code>binomcdf(n, p, min, max)</code>
<ul>
<li><code>n</code>: Anzahl Versuche</li>
<li><code>p</code>: Erfolgswahrscheinlichkeit</li>
<li><code>min</code>: Min. Anzahl Erfolge (inklusive)</li>
<li><code>max</code>: Max. Anzahl Erfolge (inklusive), <strong>optional</strong></li>
</ul></li>
<li><span class="math inline">normpdf(x, \mu, \sigma)</span></li>
<li><span class="math inline">normcdf(min, max, \mu, \sigma)</span>; <code>min</code> &amp; <code>max</code> sind nicht mehr zwingend ganzzahlig</li>
</ul>
<h3 id="wörterbuch-zur-deutschen-rechtschreibung">Wörterbuch zur deutschen Rechtschreibung</h3>
<p>Beinahe irrelevant.</p>
</body>
</html>
